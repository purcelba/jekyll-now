---
layout: post
title: RentApp | Model-based rental pricing evaluation
---
<br>
![Logos]({{ site.baseurl }}/images/streeteasy_logo.png "Streeteasy_logo.")
<br>
<br>
<br>
New York City consistently ranks among the most expensive big cities in the United States to rent an apartment (Fig. 1).  Many factors determine rental prices and apartment-seekers could benefit substantially from a simple metric to evaluate whether the price of the apartment is justified.  Put simply - How can I tell if I’m getting ripped off?

![Figure 1]({{ site.baseurl }}/images/zillow_rental.png "Zillow rental data.")
<p align="center">
<font size="2"><b>Figure 1.</b> New York rental prices are consistently among the most expensive in the country.  Median monthly rental price for the 10 largest US metropolitan areas over the past six years and US average. Raw data were obtained from [Zillow Research Data](https://www.zillow.com/research/data/) and with Matplotlib and Seaborn libraries.</font>
</p>

The project had three overall goals to extract value from data:
- I developed a web scraper to obtain a rich data set of rental listings from [Streeteasy.com](https://www.streeteasy.com).  Most publically available data only provides course aggregate data, but my data set provides individual listing information and novel features (e.g., nearby transportation, detailed amenities).
- I developed a model to predict rental prices based on the scraped data set.  I used the model to determine what features most strongly impact rental prices.
- I integrated the model into a web application to provide non-technical users with clear visualizations comparing actual and expected listing prices.

# Data overview

I obtained the data by writing a web-scraping program to retrieve information about individual listings from the online rental site Streeteasy.com.  The web scraping code is available at the [streetasy_scrape](https://github.com/purcelba/streeteasy_scrape) respository. Briefly, I navigated pages using Beautiful Soup, a standard Python package for processing HTML.  The program was executed daily over a three-month period (11/02/2016 – 1/31/2017).  For each scrape, the program retrieved every available rental listing (~27,000 listings per scrape). Key variables were collected for each listing including price, square feet, bed rooms, unit type (e.g., rental unit, condo, town house, etc), days on the market, amenities (e.g., bike room, doorman, washer/dryer in unit, etc), and distance to nearby subway lines and train stations.  You can find more details and download the data set from the [streeteasy_scrap](https://github.com/purcelba/streeteasy_scrape) repository.

![Figure 2]({{ site.baseurl }}/images/rentapp_waldorf.png "Waldorf Astoria.")
<p align="center">
<font size="2"><b>Figure 2.</b> The most expensive listing in the data set. </font>
</p>

The overall distribution of prices was positively skewed. I restricted my analyses to listings under $20,000 per month (99.27% of total data set) to avoid an undue influence of outliers (i.e., ultra-luxury apartments) that may require a separate model.  An alternative would be to adopt a nonlinear modeling approach that better handles outliers.  

![Figure 3]({{ site.baseurl }}/images/rentapp_price_dist.png "Price distribution.")
<p align="center">
<font size="2"><b>Figure 3.</b> The distribution of prices in the final data set. </font>
</p>

As expected, for units that did include square footage, there was a strong interaction with location.  The price per square foot was highest in Manhattan and lowest in Bronx.  The relationship was reasonably linear except in the upper tail, suggesting that higher order terms or nonlinear models may be useful.

![Figure 4]({{ site.baseurl }}/images/rentapp_price_sqft.png "Price square feet.")
<p align="center">
<font size="2"><b>Figure 4.</b> Mean price by square foot. </font>
</p>

I looked into the relationship between price and nearby transportation.  Ignoring all other factors, the rental price increased steeply with the number of subway stops within 1.5 mi.  Additionally, there was a clear influence of distance on the overall rental price, suggesting that distance to transportation seems to be an important factor in determining the price of a unit. However, an important limitation of this analysis is that it fails to account for correlations with other variables (i.e., collinearity).  For example, certain Manhattan neighborhoods are likely associated with both higher prices and better transportation. In the next section, I used a model-based approach to address this issue.

![Figure 5]({{ site.baseurl }}/images/rentapp_subways.png "Price subway.")
<p align="center">
<font size="2"><b>Figure 5.</b> Mean rental price increases with more nearby subway stops.  (Left) Price increases with more nearby subway stops within 1.8 miles.  (Right) Price decreases with distance from a subway line.  The relationship is roughly comparable across different lines.  Error bars are SE.   </font>
</p>

# Data preprocessing

Details of the data cleaning process are summarized in the [exporatory_analysis](https://github.com/purcelba/streeteasy_model/blob/master/notebooks/exploratory_analysis.ipynb) notebook in the GitHub repository .  The data were cleaned sorted into a dataframe using Pandas and saved to a .csv file.  Duplicate observations were dropped.  Uninformative features were dropped.  Missing values were set to zero and a new binary feature was added to indicate the presence of a missing value.  The resulting .csv files were loaded into a SQLite database for storage and final processing.  I plotted frequency distributions for all quantitative variables.  Categorical variables were encoded using one-hot-feature encoding. Outliers were eliminated based on visual inspection of the distributions and inspection of the URL associated with the listing to identify obvious data entry errors. Sadly, the $135,000/month data point was real (Fig. 3).

# Models

I evaluated a series of nested models to predict rental prices and determine which features were most informative.  For simplicity, I focused exclusively on L1-regularized linear regression.  The regularization term penalizes the model log-likelihood by adding a weighted sum of the absolute value of the coefficients.  This approach forces weights for uninformative features to zero while retaining predictive features, allowing for feature selection in the context of model fitting.  

To establish a baseline, I considered a model that used only the standard information available from the Streeteasy website API including neighborhood, number of bedrooms, and unit type.  To test whether scraped data improves performance, I evaluated a series of progressively more complex feature sets.  (1)  a model that added basic scraped data including square footage, number of days on the market, total number of rooms, and number of bathrooms, (2) a model that added features representing amenities for each listing, (3) a model that included the distances of nearby subway stops, and (4) a model that included interaction terms between neighborhood and other variables.  

For model evaluation, I used a hold-out set from the last ten days of data (6,741 listings) to quantify prediction accuracy for new listings.  I evaluated two metrics: the root mean squared error (RMSE) and R2. Both statistics were evaluated using the holdout set to control for over-fitting. R2 provides a scale-free estimate of the proportion of variance explained by the model. The RMSE gives the standard deviation of prediction errors, providing intuition about overall expected precision of the model.  

I used a non-parametric bootstrap to asses the statistical significance of prediction accuracy across models.  The bootstrap was implemented in parallel on a high-performance computing cluster using Apache Spark with PySpark API.  The code is publically available in the [parallel_bootstrap](https://github.com/purcelba/parallel_bootstrap) repository.  

The results are summarized in Fig 7.  All models that included scraped features fit significantly better than the baseline model (all p < 0.05, non-parametric bootstrap).  Including amenities in the model significantly improved the quality of fit (), but including information about transportation did not ().  Finally, there was a significant improvement in quality of fit by including interaction terms for neighborhood.

![Figure 6]({{ site.baseurl }}/images/rentapp_subways.png "Price subway.")
<p align="center">
<font size="2"><b>Figure 5.</b> RMSE and %Variance expained.   </font>
</p>




Importantly, the best performing model explained over 80% of the variance in the data (Fig 7) with a RMSE of less than $800.  This degree of accuracy is quite good given the substantial variability in the data (Fig 2) and potential unmeasured factors that determine price.  This provides a good basis to begin developing the web application.



Scraping data is time consuming, so we could potentially save a great deal of time by directly reading from the API if we are unable to surpass baseline performance.




